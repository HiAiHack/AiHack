改造验证码识别模型
  将 Tools 目录下的 VerificationCode.ipynb 文件复制到 Codelab 目录下，并将其更名为 train.ipynb。

  编辑上述文件，开始改造训练程序，在上一步中已将车牌识别程序改造完毕，因此需要在训练程序中将数据集生成的依赖替换。

import matplotlib.pyplot as plt
from PIL import Image
from GenerateCarLicensePlate import generate_car_license_plate
from GenerateCarLicensePlate import chinese
from GenerateCarLicensePlate import number
from GenerateCarLicensePlate import ALPHABET

import numpy as np
import tensorflow as tf
  本 Codelab 所采用的车牌图片的分辨率统一为 400*100，因此需要更改训练时的图像参数。

text, image = generate_car_license_plate()
print("车牌图像channel:", image.shape)
IMAGE_HEIGHT = 100
IMAGE_WIDTH = 400
MAX_CAPTCHA = len(text)
print("车牌文本最长字符数", MAX_CAPTCHA)
  同样，车牌的文本也和验证码不同，同样需要进行修改。

# 文本转向量
char_set = number + ALPHABET + chinese 
print(char_set)
CHAR_SET_LEN = len(char_set)
number_len = len(number)
ALPHABET_len = len(ALPHABET)
  数据集从验证码变成了车牌，字符字典也发生了变化，因此同样需要更改文本转向量的程序。

# 将29个字符与向量匹配
# 0 1 2 3 4 5 6 7 8 9  A  B  C  K  P  S  T  X  Y 浙 苏 沪 京 辽 鲁 闽 陕 渝 川
# 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28
def text2vec(text):
    text_len = len(text)
    if text_len > MAX_CAPTCHA:
        raise ValueError('图片字符超标')

    vector = np.zeros(MAX_CAPTCHA*CHAR_SET_LEN)
    def char2pos(c):
        if c == 'A':
            k = 10
            return k
        if c == 'B':
            k = 11
            return k
        if c == 'C':
            k = 12
            return k
        if c == 'K':
            k = 13
            return k
        if c == 'P':
            k = 14
            return k
        if c == 'S':
            k = 15
            return k
        if c == 'T':
            k = 16
            return k
        if c == 'X':
            k = 17
            return k
        if c == 'Y':
            k = 18
            return k
        if c == '浙':
            k = 19
            return k
        if c == '苏':
            k = 20
            return k
        if c == '沪':
            k = 21
            return k
        if c == '京':
            k = 22
            return k
        if c == '辽':
            k = 23
            return k
        if c == '鲁':
            k = 24
            return k
        if c == '闽':
            k = 25
            return k
        if c == '陕':
            k = 26
            return k
        if c == '渝':
            k = 27
            return k
        if c == '川':
            k = 28
            return k
        k = ord(c) - ord('0')  # 字符的ASCII码-0的ASCII码
        return k
    for i, c in enumerate(text):
        idx = i * CHAR_SET_LEN + char2pos(c)
        vector[idx] = 1
    return vector
  生成的训练 batch 也要根据实际图片进行分辨率调整。

# 生成一个训练batch
def get_next_batch(batch_size=128):
    batch_x = np.zeros([batch_size, IMAGE_HEIGHT*IMAGE_WIDTH])
    batch_y = np.zeros([batch_size, MAX_CAPTCHA*CHAR_SET_LEN])

    # 有时生成图像大小不是(100, 400, 3)
    def wrap_generate_car_license_plate():
        while True:
            text, image = generate_car_license_plate()
            if image.shape == (100, 400, 3):
                return text, image

    for i in range(batch_size):
        text, image = wrap_generate_car_license_plate()
        image = convert2gray(image)

        batch_x[i,:] = image.flatten() / 255
        batch_y[i,:] = text2vec(text)

    return batch_x, batch_y
  修改模型定义，传入图片的分辨率发生了改变，因此权重值 w_d 的 shape 也需要发生变化。

# 定义CNN
def crack_captcha_cnn(w_alpha=0.01, b_alpha=0.1):
    x = tf.reshape(X, shape=[-1, IMAGE_HEIGHT, IMAGE_WIDTH, 1])

    # 3 conv layer
    w_c1 = tf.Variable(w_alpha*tf.random_normal([3, 3, 1, 32]))
    b_c1 = tf.Variable(b_alpha*tf.random_normal([32]))
    conv1 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(x, w_c1, strides=[1, 1, 1, 1], padding='SAME'), b_c1))
    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
    conv1 = tf.nn.dropout(conv1, keep_prob)

    w_c2 = tf.Variable(w_alpha*tf.random_normal([3, 3, 32, 64]))
    b_c2 = tf.Variable(b_alpha*tf.random_normal([64]))
    conv2 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv1, w_c2, strides=[1, 1, 1, 1], padding='SAME'), b_c2))
    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
    conv2 = tf.nn.dropout(conv2, keep_prob)

    w_c3 = tf.Variable(w_alpha*tf.random_normal([3, 3, 64, 64]))
    b_c3 = tf.Variable(b_alpha*tf.random_normal([64]))
    conv3 = tf.nn.relu(tf.nn.bias_add(tf.nn.conv2d(conv2, w_c3, strides=[1, 1, 1, 1], padding='SAME'), b_c3))
    conv3 = tf.nn.max_pool(conv3, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')
    conv3 = tf.nn.dropout(conv3, keep_prob)

    # Fully connected layer
    w_d = tf.Variable(w_alpha*tf.random_normal([13*50*64, 1024]))
    b_d = tf.Variable(b_alpha*tf.random_normal([1024]))

    dense = tf.reshape(conv3, [-1, w_d.get_shape().as_list()[0]])

    dense = tf.nn.relu(tf.add(tf.matmul(dense, w_d), b_d))
    dense = tf.nn.dropout(dense, keep_prob)

    w_out = tf.Variable(w_alpha*tf.random_normal([1024, MAX_CAPTCHA*CHAR_SET_LEN]))
    b_out = tf.Variable(b_alpha*tf.random_normal([MAX_CAPTCHA*CHAR_SET_LEN]))
    out = tf.add(tf.matmul(dense, w_out), b_out)
    #out = tf.nn.softmax(out)

    return out
    
    在 Codelab 目录下新建名为 result 的目录，切换回训练程序，执行并开始训练。

